{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1217dbc8-23b4-4617-9888-caba290ff629",
   "metadata": {},
   "source": [
    "# 1.分析数据结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d82a52-f7b0-4806-957f-9000b50eb1f4",
   "metadata": {},
   "source": [
    "## 1.1 读取数据，分析有哪些column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b43c7b-4a8f-493c-8118-4d605e0b6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835ab84c-9071-4c27-ba32-ed617247a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_parquet_structure(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            path = os.path.join(folder, file)\n",
    "            df = pd.read_parquet(path, engine='pyarrow', columns=None)\n",
    "            print(f\"文件: {file}\")\n",
    "            print(df.info())\n",
    "            print(df.head(2))\n",
    "            break  # 只查看若干个样本文件即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862029c5-78f9-402e-9ba3-186ebc3c8a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件: part-00002.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5625000 entries, 0 to 5624999\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   id                 int64  \n",
      " 1   last_login         object \n",
      " 2   user_name          object \n",
      " 3   fullname           object \n",
      " 4   email              object \n",
      " 5   age                int64  \n",
      " 6   income             float64\n",
      " 7   gender             object \n",
      " 8   country            object \n",
      " 9   address            object \n",
      " 10  purchase_history   object \n",
      " 11  is_active          bool   \n",
      " 12  registration_date  object \n",
      " 13  phone_number       object \n",
      " 14  login_history      object \n",
      "dtypes: bool(1), float64(1), int64(2), object(11)\n",
      "memory usage: 606.2+ MB\n",
      "None\n",
      "         id                 last_login user_name fullname  \\\n",
      "0  11250000  2023-04-07T12:47:18+00:00    LMDCDN       仇波   \n",
      "1  11250001  2024-06-23T10:53:27+00:00     IUOLI      胥泽霖   \n",
      "\n",
      "                  email  age     income gender country        address  \\\n",
      "0    wtouqdfj@gmail.com   74  231936.85      女      美国   湖南省黑河繁荣路699号   \n",
      "1  gbwdbvgo@hotmail.com   86  176501.08      女      法国  河北省晋中海洋公园路83号   \n",
      "\n",
      "                                    purchase_history  is_active  \\\n",
      "0  {\"avg_price\":9331,\"categories\":\"笔记本电脑\",\"items\"...       True   \n",
      "1  {\"avg_price\":4430,\"categories\":\"蔬菜\",\"items\":[{...      False   \n",
      "\n",
      "  registration_date       phone_number  \\\n",
      "0        2021-12-14  +1 (041) 161-5848   \n",
      "1        2020-08-28  +33 4 63 68 60 68   \n",
      "\n",
      "                                       login_history  \n",
      "0  {\"avg_session_duration\":50,\"devices\":[\"tablet\"...  \n",
      "1  {\"avg_session_duration\":59,\"devices\":[\"mobile\"...  \n",
      "总计用时：42.31s\n"
     ]
    }
   ],
   "source": [
    "read_path = '10G_data_new'\n",
    "read_file = 'part-00000.parquet'\n",
    "\n",
    "start_time = time.time()\n",
    "preview_parquet_structure(read_path)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd64515-acc0-44b6-802c-17ab3c9128ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件: part-00008.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8437500 entries, 0 to 8437499\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   id                 int64  \n",
      " 1   last_login         object \n",
      " 2   user_name          object \n",
      " 3   fullname           object \n",
      " 4   email              object \n",
      " 5   age                int64  \n",
      " 6   income             float64\n",
      " 7   gender             object \n",
      " 8   country            object \n",
      " 9   address            object \n",
      " 10  purchase_history   object \n",
      " 11  is_active          bool   \n",
      " 12  registration_date  object \n",
      " 13  phone_number       object \n",
      " 14  login_history      object \n",
      "dtypes: bool(1), float64(1), int64(2), object(11)\n",
      "memory usage: 909.3+ MB\n",
      "None\n",
      "         id                 last_login user_name fullname  \\\n",
      "0  67500000  2023-11-12T11:56:50+00:00  SHRMHCDP       安娜   \n",
      "1  67500001  2024-06-19T05:44:35+00:00  DUKMMLSQ      云雨泽   \n",
      "\n",
      "                  email  age     income gender country           address  \\\n",
      "0  ealjosfl@outlook.com  100  456502.05      男      英国       江苏省厦门和谐路77号   \n",
      "1      mnngrbkg@126.com   64  830963.43      女    澳大利亚  内蒙古自治区东莞博物馆路651号   \n",
      "\n",
      "                                    purchase_history  is_active  \\\n",
      "0  {\"avg_price\":7847,\"categories\":\"围巾\",\"items\":[{...      False   \n",
      "1  {\"avg_price\":7561,\"categories\":\"裤子\",\"items\":[{...       True   \n",
      "\n",
      "  registration_date     phone_number  \\\n",
      "0        2022-01-29  +44 5361 738331   \n",
      "1        2022-10-17  +61 901 718 352   \n",
      "\n",
      "                                       login_history  \n",
      "0  {\"avg_session_duration\":66,\"devices\":[\"tablet\"...  \n",
      "1  {\"avg_session_duration\":120,\"devices\":[\"tablet...  \n",
      "总计用时：57.02s\n"
     ]
    }
   ],
   "source": [
    "read_path = '30G_data_new'\n",
    "read_file = 'part-00000.parquet'\n",
    "\n",
    "start_time = time.time()\n",
    "preview_parquet_structure(read_path)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbffd15e-8f20-41d6-ab5b-47ebc1ef0bf2",
   "metadata": {},
   "source": [
    "1. 对于10G和30G，数据结构是一致的，只是规模不同，数据里面内容或许不同\n",
    "1. 数据种类：bool(1), float64(1), int64(2), object(11)\n",
    "1. 其中比较复杂的数据，有purchase_history，login_history，这两种数据预计为重点分析的数据\n",
    "1. 用时有点长了，并且打印不完全，所以筛选一部分数据，保存为parquet/csv，更方便分析处理\n",
    "1. 这里选择前1000条，进行少量数据分析，不直接全量分析，减少探索时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58b92f-df00-40e0-8aef-bbbcf8253d0d",
   "metadata": {},
   "source": [
    "## 1.2 挑选部分数据进行初步类型分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9ed66b-3976-442f-8e4d-26dfa847c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet2csv(path, p_file, c_file):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    df = pd.read_parquet(os.path.join(path, p_file), engine='pyarrow', columns=None)\n",
    "    df_ = df.head(1000)\n",
    "    # 保存到csv文件（以便打开阅读）\n",
    "    df_.to_csv(os.path.join(path, c_file))\n",
    "    # 保存到新的 Parquet 文件\n",
    "    output_path = os.path.join(path, \"parquet-00000-1000.parquet\")\n",
    "    df_.to_parquet(output_path, engine='pyarrow')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e7f8b1-17ce-4d9d-844d-5c84f6f37ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计用时：39.67s\n"
     ]
    }
   ],
   "source": [
    "read_path = '10G_data_new'\n",
    "read_file = 'part-00000.parquet'\n",
    "csv_file = 'part-00000-1000.csv'\n",
    "\n",
    "start_time = time.time()\n",
    "parquet2csv(read_path, read_file, csv_file)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9508a-5f6c-42c0-8cdd-eceec1b0878f",
   "metadata": {},
   "source": [
    "下面先具体分析一下数据结构，确认数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c1011d-8faa-4f05-bfe7-8a160f04ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def inspect_parquet_row(file_path, row_index=0):\n",
    "    print(f\"读取文件: {file_path}\")\n",
    "\n",
    "    # 只读取指定行\n",
    "    df = pd.read_parquet(file_path)\n",
    "    row = df.iloc[row_index]\n",
    "    print(f\"\\n=== 分析行 {row_index} ===\\n\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        value = row[col]\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"  Type: {type(value)}\")\n",
    "        print(f\"  Value: {str(value)[:300]}\")  # 避免打印太长\n",
    "        print()\n",
    "\n",
    "        # 如果是 purchase_history 或 login_history，尝试 json.loads\n",
    "        if col in ['purchase_history', 'login_history']:\n",
    "            try:\n",
    "                parsed = json.loads(value)\n",
    "                print(f\"  → Parsed JSON keys: {list(parsed.keys())}\")\n",
    "                if isinstance(parsed, dict):\n",
    "                    for k, v in parsed.items():\n",
    "                        print(f\"    {k}: {type(v)} -> {str(v)[:100]}\")\n",
    "                print()\n",
    "            except Exception as e:\n",
    "                print(f\"JSON 解码失败：{e}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b22e41f-50fa-4245-9e6f-0e6a559813ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取文件: 10G_data_new/parquet-00000-1000.parquet\n",
      "\n",
      "=== 分析行 0 ===\n",
      "\n",
      "Column: id\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 0\n",
      "\n",
      "Column: last_login\n",
      "  Type: <class 'str'>\n",
      "  Value: 2024-12-02T03:49:12+00:00\n",
      "\n",
      "Column: user_name\n",
      "  Type: <class 'str'>\n",
      "  Value: RKWKCXRZFV\n",
      "\n",
      "Column: fullname\n",
      "  Type: <class 'str'>\n",
      "  Value: 瞿紫玉\n",
      "\n",
      "Column: email\n",
      "  Type: <class 'str'>\n",
      "  Value: kuegujsk@hotmail.com\n",
      "\n",
      "Column: age\n",
      "  Type: <class 'numpy.int64'>\n",
      "  Value: 82\n",
      "\n",
      "Column: income\n",
      "  Type: <class 'numpy.float64'>\n",
      "  Value: 366311.83\n",
      "\n",
      "Column: gender\n",
      "  Type: <class 'str'>\n",
      "  Value: 女\n",
      "\n",
      "Column: country\n",
      "  Type: <class 'str'>\n",
      "  Value: 美国\n",
      "\n",
      "Column: address\n",
      "  Type: <class 'str'>\n",
      "  Value: Non-Chinese Address Placeholder\n",
      "\n",
      "Column: purchase_history\n",
      "  Type: <class 'str'>\n",
      "  Value: {\"avg_price\":9496,\"categories\":\"零食\",\"items\":[{\"id\":7265}],\"payment_method\":\"现金\",\"payment_status\":\"已支付\",\"purchase_date\":\"2023-07-30\"}\n",
      "\n",
      "  → Parsed JSON keys: ['avg_price', 'categories', 'items', 'payment_method', 'payment_status', 'purchase_date']\n",
      "    avg_price: <class 'int'> -> 9496\n",
      "    categories: <class 'str'> -> 零食\n",
      "    items: <class 'list'> -> [{'id': 7265}]\n",
      "    payment_method: <class 'str'> -> 现金\n",
      "    payment_status: <class 'str'> -> 已支付\n",
      "    purchase_date: <class 'str'> -> 2023-07-30\n",
      "\n",
      "Column: is_active\n",
      "  Type: <class 'numpy.bool_'>\n",
      "  Value: False\n",
      "\n",
      "Column: registration_date\n",
      "  Type: <class 'str'>\n",
      "  Value: 2024-10-31\n",
      "\n",
      "Column: phone_number\n",
      "  Type: <class 'str'>\n",
      "  Value: +1 (804) 855-6279\n",
      "\n",
      "Column: login_history\n",
      "  Type: <class 'str'>\n",
      "  Value: {\"avg_session_duration\":105,\"devices\":[\"desktop\",\"mobile\"],\"first_login\":\"2024-12-04\",\"locations\":[\"home\",\"travel\"],\"login_count\":73,\"timestamps\":[\"2024-12-04 21:29:00\",\"2024-12-12 20:51:00\",\"2024-12-20 19:00:00\",\"2024-12-28 10:58:00\",\"2025-01-05 06:58:00\",\"2025-01-13 21:55:00\",\"2025-01-21 18:03:00\"\n",
      "\n",
      "  → Parsed JSON keys: ['avg_session_duration', 'devices', 'first_login', 'locations', 'login_count', 'timestamps']\n",
      "    avg_session_duration: <class 'int'> -> 105\n",
      "    devices: <class 'list'> -> ['desktop', 'mobile']\n",
      "    first_login: <class 'str'> -> 2024-12-04\n",
      "    locations: <class 'list'> -> ['home', 'travel']\n",
      "    login_count: <class 'int'> -> 73\n",
      "    timestamps: <class 'list'> -> ['2024-12-04 21:29:00', '2024-12-12 20:51:00', '2024-12-20 19:00:00', '2024-12-28 10:58:00', '2025-0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_parquet_row(\"10G_data_new/parquet-00000-1000.parquet\", row_index=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136eb92-76ae-47ae-9c14-4a8fc5850517",
   "metadata": {},
   "source": [
    "字段如下：\n",
    "\n",
    "| 字段名 | 含义 | 类型 | 特征说明 |\n",
    "|--------|------|------|---------|\n",
    "| id | 用户唯一标识 | int64 | 无需处理，可直接使用 |\n",
    "| last_login | 最近登录时间 | object (ISO时间) | 时间格式需转换 |\n",
    "| user_name | 用户名 | object | 唯一性可检查，可脱敏 |\n",
    "| fullname | 用户全名 | object | 可拆分姓与名 |\n",
    "| email | 电子邮件 | object | 可提取邮箱域名 |\n",
    "| age | 年龄 | int64 | 可检查异常值与分箱 |\n",
    "| income | 收入 | float64 | 可标准化或分箱处理 |\n",
    "| gender | 性别 | object | 类别型，需标准化编码 |\n",
    "| country | 国家 | object | 类别型，合并小众国家 |\n",
    "| address | 地址 | object | 可选处理，如地理编码 |\n",
    "| purchase_history | 购买记录（JSON） | object | 需解析为结构化字段 |\n",
    "| is_active | 是否活跃 | bool | 可直接使用 |\n",
    "| registration_date | 注册时间 | object (ISO时间) | 时间格式需转换 |\n",
    "| phone_number | 电话号码 | object | 可格式标准化，提取国家码 |\n",
    "| login_history | 登录记录（JSO） | object | 需展\n",
    "\n",
    "开提取如活跃天数、设备等特征 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89ecdc-5040-4802-9bae-011db922a16f",
   "metadata": {},
   "source": [
    "这里复制了一份涉及到两个复杂嵌套结构的东西\n",
    "\tpurchase_history\n",
    "{\"avg_price\":9496,\"categories\":\"零食\",\"items\":[{\"id\":7265}],\"payment_method\":\"现金\",\"payment_status\":\"已支付\",\"purchase_date\":\"2023-07-30\"}\n",
    "\n",
    "不是，等会儿，谁家零食吃了1w块？\n",
    "不过这不是很重要了，主要是结构，这个里面的嵌套结构有\n",
    "- avg_price, int\n",
    "- categories, str\n",
    "- items, list-dict\n",
    "- payment_method, str\n",
    "- payment_status, str\n",
    "- purchase_date, datetime(yyyy-mm-dd)\n",
    "\n",
    "\tlogin_history\n",
    "{\"avg_session_duration\":105,\"devices\":[\"desktop\",\"mobile\"],\"first_login\":\"2024-12-04\",\"locations\":[\"home\",\"travel\"],\"login_count\":73,\"timestamps\":[\"2024-12-04 21:29:00\",\"2024-12-12 20:51:00\",\"2024-12-20 19:00:00\",\"2024-12-28 10:58:00\",\"2025-01-05 06:58:00\",\"2025-01-13 21:55:00\",\"2025-01-21 18:03:00\",\"2025-01-29 18:26:00\",\"2025-02-06 19:31:00\",\"2025-02-14 11:15:00\",\"2025-02-22 06:41:00\",\"2025-03-02 10:10:00\",\"2025-03-10 20:17:00\",\"2025-03-18 20:19:00\"]}\n",
    "\n",
    "同理，login数据似乎看起来更长一些\n",
    "- avg_session_duration, int\n",
    "- devices, list-str\n",
    "- first_login, datetime(yyyy-mm-dd)\n",
    "- locations, list-str\n",
    "- login_count, int\n",
    "- timestamps, list-datetime(yyyy-mm-dd hh-mm-ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ba818-2c27-4bbd-8f90-1ca0a1004d82",
   "metadata": {},
   "source": [
    "## 1.3 简单预处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523d982-27d2-46ac-9fa9-43dff4d2e62f",
   "metadata": {},
   "source": [
    "已经分析出各种数据的结构，那么就可以进行初筛，包括\n",
    "- 缺失值分析\n",
    "- 重复值分析\n",
    "- 乱码\n",
    "- 极端值\n",
    "    - 年龄（<0 / >100）\n",
    "\n",
    "至于其他的数据处理，比如异常值（性别为“武装直升机”），建议进行统计处理，比如实现一个class，统计一些类别的出现频次，然后可视化/分析。这些会在第二部分代码实现，因为已经涉及到对数据的分析处理了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825670cd-c381-43c0-ac58-eb85279dd1ad",
   "metadata": {},
   "source": [
    "理论上讲这些分析应该单独实现，但是问题是数据量实在是太大了，逐一分析会导致重复读取，浪费大量时间，因此选择实现一个汇总的代码，读取一次分析上述所有特殊情况\n",
    "\n",
    "当然，这里不会直接进行处理，是先扫一遍，看看有没有出现上面的问题。如果有的话再决定后面怎么处理，直接删除/插值等方案都是备选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c482cdb-b2fd-4fc5-a414-63e0ad609638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_garbled(s):\n",
    "    \"\"\"检测字符串是否包含明显乱码（非 ASCII + 非常见中日韩字符）\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return False\n",
    "    return bool(re.search(r'[^\\u4e00-\\u9fa5\\u3040-\\u30ff\\uac00-\\ud7af\\w\\s\\.\\,\\-\\+\\@\\:\\(\\)/]', s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7c5c70-9089-47cb-b54b-46aa5a0204b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parquet_files(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            print(f\"正在分析: {file}\")\n",
    "            path = os.path.join(folder, file)\n",
    "            df = pd.read_parquet(path, engine='pyarrow', columns=None)\n",
    "\n",
    "            print(f\"  - 总行数: {len(df)}\")\n",
    "    \n",
    "            # 1. 缺失值分析\n",
    "            sstart_time = time.time()\n",
    "            print(\"1.缺失值分析\")\n",
    "            missing_counts = df.isnull().sum()\n",
    "            missing_counts = missing_counts[missing_counts > 0]\n",
    "            if not missing_counts.empty:\n",
    "                print(\"每列缺失:\")\n",
    "                print(missing_counts.to_string())\n",
    "            else:\n",
    "                print(\"很好，无缺失值！\")\n",
    "            end_time = time.time()\n",
    "            print(f\"这一部分用时：{(end_time-sstart_time):.2f}s\")\n",
    "    \n",
    "            # 2. 重复值分析\n",
    "            start_time = time.time()\n",
    "            print(\"2.重复值分析\")\n",
    "            duplicate_count = df.duplicated().sum()\n",
    "            print(f\"重复行数: {duplicate_count}\")\n",
    "            end_time = time.time()\n",
    "            print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "    \n",
    "            # 3. 乱码检测（仅检测 object 类型）\n",
    "            start_time = time.time()\n",
    "            print(\"3.乱码检测\")\n",
    "            garbled_counts = {}\n",
    "            for col in df.select_dtypes(include=['object']).columns:\n",
    "                garbled_rows = df[col].dropna().apply(is_garbled)\n",
    "                count = garbled_rows.sum()\n",
    "                if count > 0:\n",
    "                    garbled_counts[col] = count\n",
    "            if garbled_counts:\n",
    "                print(\"这里出现了乱码:\")\n",
    "                for col, count in garbled_counts.items():\n",
    "                    print(f\"    - {col}: {count} rows\")\n",
    "            else:\n",
    "                print(\"很好！文件很标准，无乱码出现！\")\n",
    "            end_time = time.time()\n",
    "            print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "    \n",
    "            # 4. 年龄极端值\n",
    "            start_time = time.time()\n",
    "            print(\"4.极端值-年龄\")\n",
    "            if 'age' in df.columns:\n",
    "                extreme_ages = df[(df['age'] < 0) | (df['age'] > 100)]\n",
    "                print(f\"极端年龄 (<0 or >100): {len(extreme_ages)}\")\n",
    "            else:\n",
    "                print(\"太好了，没有胚胎/修士出现在这份数据中！\")\n",
    "            end_time = time.time()\n",
    "            print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "\n",
    "            print(f\"总计用时：{(end_time-sstart_time):.2f}s\")\n",
    "            print(\"-\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e68d7a-82ef-469e-ac9d-128ca0f5417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: part-00002.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.72s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：47.68s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：150.34s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：209.77s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00006.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：10.49s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：46.02s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：146.50s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：203.04s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00004.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：10.14s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：41.28s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：152.06s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：203.51s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00000.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：10.51s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：43.89s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：145.14s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：199.58s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00003.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.37s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：42.40s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：145.98s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：199.78s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00001.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：9.03s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：44.00s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：146.81s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：199.86s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00007.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：9.65s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：41.18s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：148.22s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.06s\n",
      "总计用时：199.12s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: part-00005.parquet\n",
      "  - 总行数: 5625000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：8.30s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：41.48s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 5625000 rows\n",
      "    - login_history: 5625000 rows\n",
      "这一部分用时：151.27s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：201.07s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: parquet-00000-1000.parquet\n",
      "  - 总行数: 1000\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：0.00s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：0.01s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 1000 rows\n",
      "    - login_history: 1000 rows\n",
      "这一部分用时：0.03s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.00s\n",
      "总计用时：0.04s\n",
      "------------------------------------------------------------\n",
      "\n",
      "总计用时：1930.29s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "analyze_parquet_files(\"10G_data_new\")\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b799d13-a52b-4c6f-a2b1-761864cec4c0",
   "metadata": {},
   "source": [
    "10G的数据用了接近33min，分析过程中主要耗时在乱码检测。检测到的乱码出现在最后一行，这个事情是有点怪的，因为我看到拿到的前1000行的csv是没有问题的\n",
    "\n",
    "经过分析查证，应该和数据结构有关，最后一行会有文档结束标志，这个东西或许被识别为乱码了，而且恰好出现在两个嵌套结构中\n",
    "\n",
    "所以以上涉及到的检测都没有问题，这份数据通过了预检测，目前看来不需要进行缺失值处理、异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c211c-973e-4594-8bea-1312138cfe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: part-00008.parquet\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "analyze_parquet_files(\"30G_data_new\")\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d629e-6e50-4b50-84c8-608286d9798b",
   "metadata": {},
   "source": [
    "30G的东西实在是太多了，2h分析notebook会kernel stop，所以我这里一个个执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e87547-0c67-4ab2-b9d2-2e628c565d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parquet_files_list(file_list):\n",
    "    for file_path in file_list:\n",
    "        print(f\"正在分析: {file_path}\")\n",
    "        df = pd.read_parquet(file_path, engine='pyarrow', columns=None)\n",
    "\n",
    "        print(f\"  - 总行数: {len(df)}\")\n",
    "\n",
    "        # 1. 缺失值分析\n",
    "        sstart_time = time.time()\n",
    "        print(\"1.缺失值分析\")\n",
    "        missing_counts = df.isnull().sum()\n",
    "        missing_counts = missing_counts[missing_counts > 0]\n",
    "        if not missing_counts.empty:\n",
    "            print(\"每列缺失:\")\n",
    "            print(missing_counts.to_string())\n",
    "        else:\n",
    "            print(\"很好，无缺失值！\")\n",
    "        end_time = time.time()\n",
    "        print(f\"这一部分用时：{(end_time-sstart_time):.2f}s\")\n",
    "\n",
    "        # 2. 重复值分析\n",
    "        start_time = time.time()\n",
    "        print(\"2.重复值分析\")\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(f\"重复行数: {duplicate_count}\")\n",
    "        end_time = time.time()\n",
    "        print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "\n",
    "        # 3. 乱码检测（仅检测 object 类型）\n",
    "        start_time = time.time()\n",
    "        print(\"3.乱码检测\")\n",
    "        garbled_counts = {}\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            garbled_rows = df[col].dropna().apply(is_garbled)\n",
    "            count = garbled_rows.sum()\n",
    "            if count > 0:\n",
    "                garbled_counts[col] = count\n",
    "        if garbled_counts:\n",
    "            print(\"这里出现了乱码:\")\n",
    "            for col, count in garbled_counts.items():\n",
    "                print(f\"    - {col}: {count} rows\")\n",
    "        else:\n",
    "            print(\"很好！文件很标准，无乱码出现！\")\n",
    "        end_time = time.time()\n",
    "        print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "\n",
    "        # 4. 年龄极端值\n",
    "        start_time = time.time()\n",
    "        print(\"4.极端值-年龄\")\n",
    "        if 'age' in df.columns:\n",
    "            extreme_ages = df[(df['age'] < 0) | (df['age'] > 100)]\n",
    "            print(f\"极端年龄 (<0 or >100): {len(extreme_ages)}\")\n",
    "        else:\n",
    "            print(\"太好了，没有胚胎/修士出现在这份数据中！\")\n",
    "        end_time = time.time()\n",
    "        print(f\"这一部分用时：{(end_time-start_time):.2f}s\")\n",
    "\n",
    "        print(f\"总计用时：{(end_time-sstart_time):.2f}s\")\n",
    "        print(\"-\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b04c59-265c-40e8-ad25-ca13fac2a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: 30G_data_new/part-00000.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：13.75s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：71.85s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：208.55s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：294.17s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00001.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：13.34s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：66.52s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：221.09s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：300.97s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00002.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：16.50s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：66.07s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：205.63s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：288.22s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00003.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：13.90s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：71.63s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：223.78s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：309.33s\n",
      "------------------------------------------------------------\n",
      "\n",
      "总计用时：1406.77s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "files = [\"30G_data_new/part-00000.parquet\", \"30G_data_new/part-00001.parquet\", \"30G_data_new/part-00002.parquet\", \"30G_data_new/part-00003.parquet\", ]\n",
    "analyze_parquet_files_list(files)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664d5760-2fb4-479f-ace9-665a9776223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: 30G_data_new/part-00004.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：12.46s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：74.20s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：196.28s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：282.97s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00005.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：16.99s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：70.73s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：205.15s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.04s\n",
      "总计用时：292.91s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00006.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：15.53s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：72.64s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：205.95s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：294.15s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00007.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：12.25s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：79.70s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：201.47s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：293.45s\n",
      "------------------------------------------------------------\n",
      "\n",
      "总计用时：1385.52s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "files = [\"30G_data_new/part-00004.parquet\", \"30G_data_new/part-00005.parquet\", \"30G_data_new/part-00006.parquet\", \"30G_data_new/part-00007.parquet\", ]\n",
    "analyze_parquet_files_list(files)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0951e06-25ae-49da-a2e8-ee1718bbf1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: 30G_data_new/part-00008.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.63s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：74.05s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：193.52s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.09s\n",
      "总计用时：279.29s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00009.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：14.59s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：68.48s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：208.54s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：291.63s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00010.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.33s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：65.49s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：189.88s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：266.73s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00011.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.67s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：66.39s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：184.02s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：262.11s\n",
      "------------------------------------------------------------\n",
      "\n",
      "总计用时：1316.31s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "files = [\"30G_data_new/part-00008.parquet\", \"30G_data_new/part-00009.parquet\", \"30G_data_new/part-00010.parquet\", \"30G_data_new/part-00011.parquet\", ]\n",
    "analyze_parquet_files_list(files)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8924f2b-460d-4641-890e-55c8b0aca81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析: 30G_data_new/part-00012.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：11.93s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：67.22s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：193.06s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：272.23s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00013.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：12.41s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：66.41s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：196.00s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：274.84s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00014.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：10.64s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：66.63s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：197.61s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.03s\n",
      "总计用时：274.91s\n",
      "------------------------------------------------------------\n",
      "\n",
      "正在分析: 30G_data_new/part-00015.parquet\n",
      "  - 总行数: 8437500\n",
      "1.缺失值分析\n",
      "很好，无缺失值！\n",
      "这一部分用时：10.34s\n",
      "2.重复值分析\n",
      "重复行数: 0\n",
      "这一部分用时：69.19s\n",
      "3.乱码检测\n",
      "这里出现了乱码:\n",
      "    - purchase_history: 8437500 rows\n",
      "    - login_history: 8437500 rows\n",
      "这一部分用时：197.91s\n",
      "4.极端值-年龄\n",
      "极端年龄 (<0 or >100): 0\n",
      "这一部分用时：0.02s\n",
      "总计用时：277.46s\n",
      "------------------------------------------------------------\n",
      "\n",
      "总计用时：1314.28s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "files = [\"30G_data_new/part-00012.parquet\", \"30G_data_new/part-00013.parquet\", \"30G_data_new/part-00014.parquet\", \"30G_data_new/part-00015.parquet\", ]\n",
    "analyze_parquet_files_list(files)\n",
    "end_time = time.time()\n",
    "print(f\"总计用时：{(end_time-start_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5b83f-e212-4760-9c99-9b91b15c053e",
   "metadata": {},
   "source": [
    "30G的数据时间更夸张，每一个文件5min，24个文件大概用了2h上下，分析过程中主要耗时在乱码检测。检测到的乱码出现在最后一行，这个事情是有点怪的，因为我看到拿到的前1000行的csv是没有问题的\n",
    "\n",
    "经过分析查证，应该和数据结构有关，最后一行会有文档结束标志，这个东西或许被识别为乱码了，而且恰好出现在两个嵌套结构中\n",
    "\n",
    "所以以上涉及到的检测都没有问题，这份数据通过了预检测，目前看来不需要进行缺失值处理、异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56d06a-eb67-4443-902d-1a7186dcc341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastSAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
